<!DOCTYPE html>
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<!-- three.js library -->
<script src='./src/three.min.js'></script>
<!-- ar.js -->
<script src="./src/ar-threex.js"></script>
<script>THREEx.ArToolkitContext.baseURL = '../'</script>

<body style='font-family: Monospace;'>
	<div style='position: absolute; top: 10px; width:100%; text-align: center; z-index: 1;'>
	</div>
	<script>
		//////////////////////////////////////////////////////////////////////////////////
		//		Init
		//////////////////////////////////////////////////////////////////////////////////

		// init renderer
		var renderer = new THREE.WebGLRenderer({
			antialias: true,
			alpha: true
		});
		renderer.setClearColor(new THREE.Color('lightgrey'), 0)
		renderer.setSize(640, 480);
		renderer.domElement.style.position = 'absolute'
		renderer.domElement.style.top = '0px'
		renderer.domElement.style.left = '0px'
		document.body.appendChild(renderer.domElement);

		// array of functions for the rendering loop
		var onRenderFcts = [];
		var arToolkitContext, arMarkerControls;

		// init scene and camera
		var scene = new THREE.Scene();

		//////////////////////////////////////////////////////////////////////////////////
		//		Initialize a basic camera
		//////////////////////////////////////////////////////////////////////////////////

		// Create a camera
		var camera = new THREE.Camera();
		scene.add(camera);

		////////////////////////////////////////////////////////////////////////////////
		//          handle arToolkitSource
		////////////////////////////////////////////////////////////////////////////////

		var arToolkitSource = new THREEx.ArToolkitSource({
			// to read from the webcam
			sourceType: 'webcam',

			sourceWidth: window.innerWidth > window.innerHeight ? 640 : 480,
			sourceHeight: window.innerWidth > window.innerHeight ? 480 : 640,

			// // to read from an image
			// sourceType : 'image',
			// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/images/img.jpg',

			// to read from a video
			// sourceType : 'video',
			// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/videos/headtracking.mp4',
		})

		arToolkitSource.init(function onReady() {
			arToolkitSource.domElement.addEventListener('canplay', () => {
				console.log(
					'canplay',
					'actual source dimensions',
					arToolkitSource.domElement.videoWidth,
					arToolkitSource.domElement.videoHeight
				);

				initARContext();
			});
			window.arToolkitSource = arToolkitSource;
			setTimeout(() => {
				onResize()
			}, 2000);
		})

		// handle resize
		window.addEventListener('resize', function () {
			onResize()
		})

		function onResize() {
			arToolkitSource.onResizeElement()
			arToolkitSource.copyElementSizeTo(renderer.domElement)
			if (window.arToolkitContext.arController !== null) {
				arToolkitSource.copyElementSizeTo(window.arToolkitContext.arController.canvas)
			}
		}
		////////////////////////////////////////////////////////////////////////////////
		//          initialize arToolkitContext
		////////////////////////////////////////////////////////////////////////////////


		function initARContext() { // create atToolkitContext
			arToolkitContext = new THREEx.ArToolkitContext({
				cameraParametersUrl: './data/camera_para.dat',
				detectionMode: 'mono'
			})
			// initialize it
			arToolkitContext.init(() => { // copy projection matrix to camera
				camera.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());

				arToolkitContext.arController.orientation = getSourceOrientation();
				arToolkitContext.arController.options.orientation = getSourceOrientation();

				console.log('arToolkitContext', arToolkitContext);
				window.arToolkitContext = arToolkitContext;
			})
			scene.visible = true

		}


		function getSourceOrientation() {
			if (!arToolkitSource) {
				return null;
			}

			console.log(
				'actual source dimensions',
				arToolkitSource.domElement.videoWidth,
				arToolkitSource.domElement.videoHeight
			);

			if (arToolkitSource.domElement.videoWidth > arToolkitSource.domElement.videoHeight) {
				console.log('source orientation', 'landscape');
				return 'landscape';
			} else {
				console.log('source orientation', 'portrait');
				return 'portrait';
			}
		}

		// update artoolkit on every frame
		onRenderFcts.push(function () {
			if (!arToolkitContext || !arToolkitSource || !arToolkitSource.ready) {
				return;
			}

			arToolkitContext.update(arToolkitSource.domElement)

			// update scene.visible if the marker is seen
			scene.visible = camera.visible
		})

		//////////////////////////////////////////////////////////////////////////////////
		//		add an object in the scene
		//////////////////////////////////////////////////////////////////////////////////


        //添加立方体
        const geometry2 = new THREE.BoxGeometry( 1, 1, 1 );//立方体对象，包含立方体中的顶点(vertices)和面(faces)
        // const material2 = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );//添加材质，让立方体有颜色
        const material2 = [
            new THREE.MeshBasicMaterial({ color: 0xff0000 }),
            new THREE.MeshBasicMaterial({ color: 0x0000ff }),
            new THREE.MeshBasicMaterial({ color: 0x00ff00 }),
            new THREE.MeshBasicMaterial({ color: 0xff00ff }),
            new THREE.MeshBasicMaterial({ color: 0x00ffff }),
            new THREE.MeshBasicMaterial({ color: 0xffff00 })
        ];
        let minx = -0.5, miny = -1, minz= -15;
        let maxx = 0.5, maxy=1, maxz=-3;
        let edgeNum=4;
        for(let i=0;i<edgeNum;++i){
            for(let j=0;j<edgeNum;++j){
                for(let k=0;k<edgeNum;++k){
                    const cube = new THREE.Mesh( geometry2, material2 );//网格包括一个几何体以及作用在几何体上的材质，可以直接将网格对象放到场景中，并且让他自由移动
                    if(edgeNum===1){
                        cube.position.set(minx, miny,minz);
                        cube.scale.set( 0.1, 0.1, 0.1 );
                        scene.add( cube );//添加立方体，默认坐标是(0,0,0)，会与摄像机重合
                    }else{
                        let curx = minx + (maxx-minx)/(edgeNum-1)*i;
                        let cury = miny+ (maxy-miny)/(edgeNum-1)*j;
                        let curz = minz + (maxz-minz)/(edgeNum-1)*k;
                        cube.position.set(curx, cury,curz);
                        cube.scale.set( 0.1, 0.1, 0.1 );
                        scene.add( cube );//添加立方体，默认坐标是(0,0,0)，会与摄像机重合
                    }
                    
                }
            }
        }

		//////////////////////////////////////////////////////////////////////////////////
		//		render the whole thing on the page
		//////////////////////////////////////////////////////////////////////////////////

		// render the scene
		onRenderFcts.push(function () {
			renderer.render(scene, camera);
		})

		// run the rendering loop
		var lastTimeMsec = null
		requestAnimationFrame(function animate(nowMsec) {
			// keep looping
			requestAnimationFrame(animate);
			// measure time
			lastTimeMsec = lastTimeMsec || nowMsec - 1000 / 60
			var deltaMsec = Math.min(200, nowMsec - lastTimeMsec)
			lastTimeMsec = nowMsec
			// call each update function
			onRenderFcts.forEach(function (onRenderFct) {
				onRenderFct(deltaMsec / 1000, nowMsec / 1000)
			})
		})
	</script>
</body>